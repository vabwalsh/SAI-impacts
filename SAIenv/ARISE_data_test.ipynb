{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# geospatial plotting\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs \n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# display\n",
    "from IPython.display import Image\n",
    "from cartopy.io.img_tiles import GoogleTiles\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# handling netCDFs\n",
    "import xclim as xc\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a netCDFs downloaded from the curl script\n",
    "# read in all the netcdfs in a folder, and make a dict with the run number as the key and xarrays values\n",
    "\n",
    "def parse_data(fp_to_nc_folder):\n",
    "\n",
    "    # lists to hold the netcdfs and their run numbers \n",
    "    run_numbers = []\n",
    "    nc_names = []\n",
    "\n",
    "    # read all the files matching the input file path\n",
    "    for nc_file in glob.glob(fp_to_nc_folder):\n",
    "\n",
    "        # open them!\n",
    "        with open(os.path.join(os.getcwd(), nc_file), 'r') as f: \n",
    "\n",
    "            # extract the run number from the file name and add it to a list to ID each file\n",
    "            # this assumes all ARISE-SAI files have more or less the same filename and location of the run number within it, may need to be updated\n",
    "            run_numbers.append(pd.Series(nc_file).str.split(pat = 'DEFAULT.')[0][1].split('.cam')[0])\n",
    "\n",
    "            # open each nc file and add that to another list\n",
    "            nc_names.append(xr.open_dataset(nc_file))\n",
    "\n",
    "    # combine the lists into a dict ordered by keys (run numbers low to high)\n",
    "    data_dict = dict(sorted(dict(zip(run_numbers, nc_names)).items()))\n",
    "\n",
    "    return(data_dict)\n",
    "\n",
    "# use this function on the TMSO2 data\n",
    "TMSO2_dict = parse_data('./project-data/TMSO2/*.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMSO2_dict['001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the correct ne python -m pip install \"xarray[io]\"tCDF for so4_a1DDF\n",
    "# try to get a time seires for deposition\n",
    "# compare this to some other sulfur fluxes\n",
    "# see if this is high, low, etc."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
